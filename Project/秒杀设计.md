# 秒杀设计

首先，要**尽力将请求拦截在系统上游**，层层设阻拦截，过滤掉无效或超量的请求。因为访问量远远大于商品数量，所有的请求打到后端服务的最后一步，其实并没有必要，反而会严重拖慢真正能成交的请求，降低用户体验。

 秒杀系统专为秒杀活动服务，售卖商品确定，因此可以在设计秒杀商品页面时，将商品信息提前设计为静态信息，将静态的商品信息以及常规的 CSS、JS、宣传图片等静态资源，一起**独立存放到 CDN 节点**，加速访问，且降低系统访问压力，在访问前端也可以**制定种种限制策略，**比如活动没开始时，抢购按钮置灰，避免抢先访问，用户抢购一次后，也将按钮置灰，让用户排队等待，避免反复刷新。

 其次，要**充分利用缓存**，提升系统的性能和可用性。

 用户所有的请求进入秒杀系统前，通过**负载均衡策略**均匀分发到不同 Web 服务器，避免节点过载。在 Web 服务器中，首先检查用户的访问权限，识别并发刷订单的行为。如果发现售出数量已经达到秒杀数量，则直接返回结束，要将秒杀业务系统和其他业务系统进行功能分拆，尽量将秒杀系统及依赖服务**独立分拆部署**，避免影响其他核心业务系统。

 秒杀系统需要构建访问记录缓存，记录访问 IP、用户的访问行为，发现异常访问，提前进行阻断及返回。同时还需要**构建用户缓存**，并针对历史数据分析，提前缓存僵尸强刷专业户，方便在秒杀期间对其进行策略限制。这些访问记录、用户数据，通过缓存进行存储，可以加速访问，另外，对用户数据还进行缓存预热，避免活动期间大量穿透。





## 1. 如何解决超卖？

mysql乐观锁+redis预减库存+redis缓存卖完标记

第一是基于**数据库乐观锁**的方式保证数据并发扣减的强一致性；

第二是基于**数据库的事务**实现批量扣减部分失败时的数据回滚。

 在扣减指定数量前应先做一次前置数量校验的读请求（参考**读写分离** + **全缓存方案**）

> 纯数据库乐观锁+事务的方式性能比较差，但是如果不计成本和考虑场景的话也完全够用，因为任何没有机器配置的指标，都是耍流氓。如果我采用 Oracle 的数据库、100 多核的刀锋服务器、SSD 的硬盘，即使是纯数据库的扣减方案，也是可以达到单机上万的 TPS 的。

**单线程Redis 的 lua 脚本实现批量扣减**

当用户调用扣减接口时，将扣减的 对应数量 + 脚本标示传递至 Redis 即可，所有的扣减判断逻辑均在 Redis 中的 lua 脚本中执行，lua 脚本执行完成之后返还是否成功给客户端。

![image-20210504174103769](images/68747470733a2f2f747661312e73696e61696d672e636e2f6c617267652f3030386933736b4e6c79316771366a39646b7136766a33307732306b6f776b752e6a7067)



Redis 中的 lua 脚本执行时，首先会使用 get 命令查询 uuid 进行查重。当防重通过后，会**批量获取对应的剩余库存状态并进行判断**，如果一个扣减的数量大于剩余数量，则返回错误并提示数量不足。

Redis 的单线程模型，确保**不会出现当所有扣减数量在判断均满足后，在实际扣减时却数量不够**。同时，单线程保证判断数量的步骤和后续扣减步骤之间，没有其他任何线程出现并发的执行。

当 Redis 扣减成功后，扣减接口会**异步的将此次扣减内容保存至数据库**。异步保存数据库的目的是防止出现极端情况—— Redis 宕机后数据未持久化到磁盘，此时我们可以使用数据库恢复或者校准数据

最后，运营后台直连数据库，是运营和商家修改库存的入口。商家在运营后台进货物进行补充。同时，运营后台的实现需要将此数量**同步的增加至 Redis**，因为当前方案的所有实际扣减都在 Redis 中

> 纯缓存方案虽**不会导致超卖**，但因**缓存不具备事务特性**，极端情况下会存在缓存里的数据**无法回滚**，导致出现**少卖**的情况。且架构中的异步写库，也可能发生失败，导致多扣的数据丢失

可以借助**顺序写**的特性，将扣减任务同步**插入**任务表，发现异常时，将任务表作为**undolog**进行回滚

可以解决由于**网络不通**、调用缓存**扣减超时**、在扣减到一半时缓存**突然宕机**（故障 failover）了。针对上述请求，都有相应的异常抛出，根据异常进行**数据库回滚**即可，最终任务库里的数据都是准的

更进一步：由于任务库是无状态的，可以进行水平分库，提升整体性能





## 2. 如何解决重复下单

mysql唯一索引+分布式锁



## 3. 如何防刷

IP限流 | 验证码 | 单用户 | 单设备 | IMEI | 源IP |均设置规则





## 4. 热Key问题如何解决

redis集群+本地缓存+限流+key加随机值分布在多个实例中

1、**缓存集群**可以单节点进行**主从复制和垂直扩容**

2、利用应用内的**前置缓存**，但是需注意需要设置上限

3、延迟不敏感，**定时刷新**，实时感知用主动刷新

4、和缓存穿透一样，限制逃逸流量，单请求进行数据**回源并刷新前置**

5、无论如何设计，最后都要写一个**兜底逻辑**





## 5. 如何应对高并发的读请求

使用缓存策略将请求挡在上层中的缓存中

使用CDN，能静态化的数据尽量做到静态化，

加入限流（比如对短时间之内来自某一个用户，某一个IP、某个设备的重复请求做丢弃处理）

**资源隔离限流**会将对应的资源按照指定的类型进行隔离，比如**线程池**和**信号量**。

- 计数器限流，例如5秒内技术1000请求，超数后限流，未超数重新计数

- 滑动窗口限流，解决计数器不够精确的问题，把一个窗口拆分多滚动窗口

- 令牌桶限流，类似景区售票，售票的速度是固定的，拿到令牌才能去处理请求

- 漏桶限流，生产者消费者模型，实现了恒定速度处理请求，能够绝对防止突发流量

  流量控制效果从好到差依次是：**漏桶限流 > 令牌桶限流 > 滑动窗口限流 > 计数器限流**

![image-20210504174148831](images/68747470733a2f2f747661312e73696e61696d672e636e2f6c617267652f3030386933736b4e6c79316771366a61373336656b6a3331366f3036363430752e6a7067)



其中，只有漏桶算法**真正实现了恒定速度处理请求**，能够绝对**防止突发流量超过下游系统承载能力**。 不过，漏桶限流也有个不足，就是需要分**配内存资源缓存请求**，这会增加内存的使用率。而**令牌桶限流**算法中的“桶”可以用一个整数表示，**资源占用相对较小**，这也让它成为最常用的限流算法。正是因为这些特点，**漏桶限流和令牌桶限流**经常在一些大流量系统中结合使用。



## 6. 应对高并发的写请求

- **削峰**：恶意用户拦截

  对于单用户多次点击、单设备、IMEI、源IP均设置规则

- 采用比较成熟的**漏桶算法、令牌桶**算法，也可以使用**guava**开箱即用的限流算法

  可以集群限流，但单机限流更加简洁和稳定

- 当前层**直接过滤**一定比例的请求，最大承载值前需要加上**兜底逻辑**

- 对于已经无货的产品，**本地缓存**直接返回

- **单独部署，减少对系统正常服务的影响，方便扩缩容**

对于**一段时间内的秒杀活动，需要保证写成功**，我们可以使用 **消息队列**。

- 削去秒杀场景下的峰值写流量——**流量削峰**
- 通过异步处理简化秒杀请求中的业务流程——**异步处理**
- 解耦，实现秒杀系统模块之间松耦合——**解耦**

**削去秒杀场景下的峰值写流量**

- **将秒杀请求暂存于消息队列**，业务服务器响应用户“秒杀结果正在处理中。。。”，释放系统资源去处理其它用户的请求。
- **削峰填谷**，削平短暂的流量高峰，消息堆积会造成请求延迟处理，但秒杀用户对于短暂延迟有一定容忍度。秒杀商品有 1000 件，处理一次购买请求的时间是 500ms，那么总共就需要 500s 的时间。这时你部署 10 个队列处理程序，那么秒杀请求的处理时间就是 50s，也就是说用户需要等待 50s 才可以看到秒杀的结果，这是可以接受的。这时会**并发 10 个**请求到达数据库，并不会对数据库造成很大的压力。

**通过异步处理简化秒杀请求中的业务流程**

 先处理主要的业务，异步处理次要的业务。

- 如主要流程是**生成订单**、**扣减库存**；
- 次要流程比如购买成功之后会给用户**发优惠券**，**增加用户的积\**\**分**。
- 此时秒杀只要处理生成订单，扣减库存的耗时，发放优惠券、增加用户积分异步去处理了。

**解耦**

 实现秒杀系统模块之间松耦合将秒杀数据同步给数据团队，有两种思路：

- 使用 HTTP 或者 RPC 同步调用，即提供一个接口，实时将数据推送给数据服务。**系统的耦合度高**，如果其中一个服务有问题，可能会导致另一个服务不可用。
- 使用消息队列**将数据全部发送给消息队列**，然后**数据服务订阅这个消息队列**，接收数据进行处理。



## 7. 保证数据一致性

**CacheAside旁路缓存**读请求不命中查询数据库，查询完成写入缓存，写请求更新数据库后删除缓存数据。

~~~java
// 延迟双删，用以保证最终一致性,防止小概率旧数据读请求在第一次删除后更新数据库
public void write(String key,Object data){
	redis.delKey(key);
	db.updateData(data);
	Thread.sleep(1000);
	redis.delKey(key);
}
~~~

为防缓存失效这一信息丢失，可用消息队列确保。

- 更新数据库数据；
- 数据库会将操作信息写入binlog日志当中；
- 另起一段非业务代码，程序订阅提取出所需要的数据以及key；
- 尝试删除缓存操作，若删除失败，将这些信息发送至消息队列；
- 重新从消息队列中获得该数据，重试操作；

订阅**binlog程序在mysql中有现成的中间**件叫canal，重试机制，主要采用的是消息队列的方式。

**终极方案：请求串行化**

真正靠谱非秒杀的方案：将访问操作串行化

1. 先删缓存，将更新数据库的**写操作放进有序队列中**
2. 从缓存查不到的**读操作也进入有序队列**

需要解决的问题：

1. 读请求积压，大量超时，导致数据库的压力：限流、熔断
2. 如何避免大量请求积压：将队列水平拆分，提高并行度。





## 8. 可靠性的保障

 由一个或多个sentinel实例组成sentinel集群可以监视一个或多个主服务器和多个从服务器。**哨兵模式适合读请求远多于写请求的业务场景，比如在秒杀系统**中用来缓存活动信息。 如果写请求较多，当集群 Slave 节点数量多了后，Master 节点同步数据的压力会非常大。

![image-20201220231241725](images/68747470733a2f2f747661312e73696e61696d672e636e2f6c617267652f303038314b636b776c7931676c757136766c76676c6a33306e773065303736662e6a7067)

 当主服务器进入下线状态时，sentinel可以将该主服务器下的某一从服务器升级为主服务器继续提供服务，从而保证redis的高可用性。



## 9. 秒杀系统瓶颈-日志

> 秒杀服务单节点需要处理的请求 QPS 可能达到 10 万以上。一个请求从进入秒杀服务到处理失败或者成功，至少会产生两条日志。也就是说，高峰期间，一个秒杀节点每秒产生的日志可能达到 **30 万条**以上

 一块性能比较好的固态硬盘，每秒写的IOPS 大概在 3 万左右。也就是说，一个秒杀节点的每秒日志条数是固态硬盘 IOPS 的 10 倍，磁盘都扛不住，更别说通过网络写入到监控系统中。

- **每秒日志量远高于磁盘 IOPS**，直接写磁盘会影响服务性能和稳定性
- 大量日志导致服务频繁分配，**频繁释放内存，影响服务性能**。
- 服务异常退出**丢失大量日志**的问题

**解决方案**

- **Tmpfs**，即临时文件系统，它是一种基于内存的文件系统。我们可以将秒杀服务写日志的文件放在临时文件系统中。相比直接写磁盘，在临时文件系统中写日志的性能至少**能提升 100 倍**，每当日志文件达到 20MB 的时候，就将**日志文件转移到磁盘上**，并将临时文件系统中的日志文件清空。
- 可以参考内存池设计，将给logger分配缓冲区，每一次的新写可以复用Logger对象
- 参考kafka的缓冲池设计，当缓冲区达到大小和间隔时长临界值时，调用Flush函数，减少丢失的风险



## 10. 池化技术

![image-20210504174220668](images/68747470733a2f2f747661312e73696e61696d672e636e2f6c617267652f3030386933736b4e6c79316771366a6170776f66326a33313532306e61346d682e6a7067)

 通常可以采用**循环队列**来保存空闲连接。使用的时候，可以从队列头部取出连接，用完后将空闲连接放到队列尾部。Netty中利用带缓冲区的 channel 来充当队列。





