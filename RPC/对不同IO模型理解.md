# IO模型

[TOC]





## 同步异步阻塞非阻塞

同步I/O与异步I/O的主要区别就在于站在应用程序的视角看，真正读取/写入数据时**是否是由应用程序主导**的。

如果需要**用户程序主动发起**最终的I/O请求就被称为同步I/O；

而如果是内核自动完成I/O后**通知用户程序**，则被称为异步I/O。(可以类比在下文硬件I/O模型中，站在CPU视角的同步、异步I/O模型，只不过这里CPU变成了应用程序，而外设/DMA变成了操作系统内核)



在处理 IO 的时候，阻塞和非阻塞都是同步 IO。
只有使用了特殊的 API 才是异步 IO。

阻塞相当于没抢到互斥锁的线程，会被挂起，不占用CPU，当锁被释放时又会被唤醒起来抢锁

非阻塞相当于没抢到自旋锁的线程，不会被挂起，会一直轮询，占用CPU，调用者不用一直等着结果返回









## 硬件IO模型

**计算机中的I/O本质上是CPU/内存与外设(网卡、磁盘等)进行数据的单向或双向传输**

从外设读入数据到CPU/内存称作Input输入，从CPU/内存中写出数据到外设称作Output输出。硬件I/O模型大致可以分为三种：**程序控制I/O、中断驱动I/O、使用DMA的I/O**。



### 程序控制I/O

通过指令控制CPU**不断的轮询**外设是否就绪，当硬件就绪时一点一点的反复读/写数据

从CPU的角度来说，程序控制I/O模型是同步、阻塞的(同步指的是I/O操作依然是处于程序指令控制，由CPU主导的；阻塞指的是在发起I/O后CPU必须持续轮询完成状态，无法执行别的指令)。



程序控制I/O的优点：

　　硬件结构简单，编写对应程序也简单。



程序控制I/O的缺点：

　　十分消耗CPU，持续的轮训令宝贵的CPU资源无谓的浪费在了等待I/O完成的过程中，导致CPU利用率不高。





### 中断驱动I/O

为了解决上述程序控制I/O模型对CPU资源利用率不高的问题，计算机硬件的设计者令CPU拥有了处理中断的功能。

在中断驱动I/O模型中，CPU发起对外设的I/O请求后，**就直接去执行别的指令了**。当硬件处理完I/O请求后，通过中断异步的**通知CPU**。接到读取完成中断通知后，CPU负责将数据从外设缓冲区中写入内存；接到写出完成中断通知后，CPU需要将内存中后续的数据接着写出交给外设处理。

从CPU的角度来说，中断驱动I/O模型是**同步、非阻塞的**(同步指的是I/O操作依然是处于程序指令控制，由CPU主导的；非阻塞指的是在发起I/O后CPU不会停下等待，而是可以执行别的指令)。



中断驱动I/O的优点：

　　由于I/O总是相对耗时的，比起通过程序控制I/O模型下CPU不停的轮训。在等待硬件I/O完成的过程中CPU可以解放出来执行另外的命令，大大提高了I/O密集程序的CPU利用率。



中断驱动I/O的缺点：

　　受制于硬件缓冲区的大小，一次硬件I/O可以处理的数据是相对有限的。在处理一次大数据的I/O请求中，**CPU需要被反复的中断**，而处理读写中断事件本身也是有一定开销的。



### DMA  I/O

为了解决中断驱动I/O模型中，大数据量的I/O传输使得CPU需要反复处理中断的缺陷，计算机硬件的设计者提出了基于DMA模式的I/O(**DMA Direct Memory Access 直接存储器访问**)。

DMA也是一种处理器芯片，和CPU一样也可以访问内存和外设，但DMA芯片是被设计来专门处理I/O数据传输的，因此其成本相对CPU较低。

　　在使用DMA的I/O模型中，CPU与DMA芯片交互，指定需要读/写的数据块大小和需要进行I/O数据的目的内存地址后，**便异步的处理别的指令了**。由DMA与外设硬件进行交互，一次大数据量的I/O需要DMA反复的与外设进行交互，当DMA完成了整体数据块的I/O后(**完整的将数据读入到内存或是完整的将某一内存块的数据写出到外设**)，再发起DMA中断通知CPU。

　　从CPU的角度来说，使用DMA的I/O模型是**异步、非阻塞的**(异步指的是整个I/O操作并不是由CPU主导，而是由DMA芯片与外设交互完成的；非阻塞指的是在发起I/O后CPU不会停下等待，而是可以执行别的指令)。



使用DMA的I/O优点：

　　比起外设硬件中断通知，对于一次完整的大数据内存与外设间的I/O，CPU只需要处理一次中断。CPU的利用效率相对来说是最高的。



使用DMA的I/O缺点：

　　1. 引入DMA芯片令硬件结构变复杂，成本较高。

　　2. 由于DMA芯片的引入，使得DMA和CPU并发的对内存进行操作，在拥有高速缓存的CPU中，引入了高速缓存与内存不一致的问题。

自DMA技术被发明以来，由于其极大减少了CPU在I/O时的性能损耗，已经成为了绝大多数通用计算机的硬件标配。随着技术的发展又出现了更先进的**通道I/O方式**，相当于并发的DMA，允许并发的处理涉及多个不同内存区域、外设硬件的I/O操作。





## 操作系统IO模型

操作系统帮我们屏蔽了诸多硬件外设的差异，为应用程序的开发者提供了友好、统一的服务。为了避免应用程序破坏操作系统内核，CPU提供了保护模式机制，使得应用程序无法直接访问被操作系统管理起来的外设，而必须通过内核提供的**系统调用**间接的访问外设。关于操作系统I/O模型的讨论针对的就是**应用程序与内核**之间进行I/O交互的系统调用模型。

常见的IO模型有如下的四种

1. 同步阻塞IO（Blocking IO）
2. 同步非阻塞IO （Non-blocking IO）
3. IO多路复用 (IO Multiplexing)
4. 异步IO （Asynchronous IO）



> 另外，还有一种信号驱动IO（内核在IO就绪发送SIGIO信号通知应用进程），不常见，信号驱动式模型的一个显著特点是用户态进程不再等待内核态的数据准备好，直接可以去做别的事情，但是等待数据从内核缓冲区拷贝到进程缓冲区仍然是阻塞的



## 同步阻塞BIO（Blocking IO）

> 高效的硬件层面I/O模型对于CPU来说是异步的，但应用程序开发者总是希望在执行完I/O系统调用后能同步的返回，线性的执行后续逻辑(例如当磁盘读取的系统调用返回后，下一行代码中就能直接访问到所读出的数据)。
>
> 但这与硬件层面耗时、异步的I/O模型相违背(程序控制I/O过于浪费CPU)
>
> 操作系统内核提供了基于同步、阻塞I/O的系统调用(BIO)来解决这一问题。



> 　　举个例子：当线程通过基于BIO的系统调用进行磁盘读取时，内核会令当前线程进入阻塞态，让出CPU资源给其它并发的就绪态线程，以便更有效率的利用CPU。当DMA完成读取，异步的I/O中断到来时，内核会找到先前被阻塞的对应线程，将其唤醒进入就绪态。当这个就绪态的线程被内核CPU调度器选中再度获得CPU时，便能从对应的缓冲区结构中得到读取到的磁盘数据，程序同步的执行流便能顺利的向下执行了。(感觉好像线程卡在了那里不动，过了一会才执行下一行，且指定的缓冲区中已经有了所需的数据)



在Java应用程序进程中，默认情况下，**所有的socket连接**的IO操作都是同步阻塞IO（Blocking IO）。

 在阻塞式IO模型中，Java应用程序**从IO系统调用开始，直到系统调用返回**，在这段时间内，Java进程是阻塞的。返回成功后，应用进程开始处理用户空间的缓存区数据。 同步阻塞IO的具体流程如下

![image-20210426140505575](images/image-20210426140505575.png)

举个例子，在Java中发起一个socket的read读操作的系统调用，流程大致如下：

 （1）从Java启动IO读的read系统调用开始，用户线程就进入阻塞状态。

 （2）当系统内核收到read系统调用，就开始准备数据。一开始，数据可能还没有到达内核缓冲区（例如，还没有收到一个完整的socket数据包），这个时候内核就要**等待**。

 （3）内核一直等到完整的数据到达，就会将数据从内核缓冲区复制到用户缓冲区（用户空间的内存），然后内核返回结果（例如返回复制到用户缓冲区中的字节数）。

 （4）直到内核返回后，**用户线程才会解除阻塞的状态，重新运行起来**。

 总之，阻塞IO的特点是：**在内核进行IO执行的两个阶段，用户线程都被阻塞了**。 



阻塞IO的优点是：应用的程序开发简单；在阻塞等待数据期间，**用户线程挂起**。

在阻塞期间，用户线程**基本不会占用CPU资源。**



阻塞IO的缺点是：

1. 一般情况下，会为每个连接配备一个**独立**的线程；反过来说，就是**一个线程维护一个连接的IO操作**。在并发量小的情况下，问题不大

   但是，当在高并发的应用场景下，需要大量的线程来维护大量的网络连接，**内存、线程切换开销会非常巨大**。因此，基本上阻塞IO模型在高并发应用场景下是不可用的。

2. 由于BIO在等待I/O完成的时间中，线程虽然被阻塞不消耗CPU，但**内核维护一个系统级线程本身也是有一定的开销**(维护线程控制块、内核线程栈空间等等)。

3. 不同线程在调度时的**上下文切换CPU开销较大**，在如今大量用户、高并发的互联网时代越来越成为web服务器性能的瓶颈。线程上下文切换本身需要需要保存、恢复现场，同时还会清空CPU指令流水线，以及令高速缓存大量失效。对于一个web服务器，如果使用BIO模型，服务器将至少需要1:1的维护同等数量的系统级线程(内核线程)，由于持续并发的网络数据交互，导致不同线程由于网络I/O的完成事件被内核反复的调度。







## 同步非阻塞NIO（Non-blocking IO）

> NIO模型的系统调用不会阻塞当前调用线程。但由于I/O本质上的耗时特性，无法立即得到I/O处理的结果，NIO的系统调用在I/O未完成时会返回特定标识，代表对应的I/O事件还未完成。因此需要应用程序按照一定的频率反复调用，以获取最新的IO状态。



socket连接默认是阻塞模式，在Linux系统下，可以通过设置将socket变成为非阻塞的模式（Non-Blocking）。

使用非阻塞模式的IO读写，叫作同步非阻塞IO（None Blocking IO），简称为NIO模式。

在 NIO模型中，应用程序一旦开始IO系统调用，会出现以下两种情况：

（1）在内核缓冲区中没有数据的情况下，系统调用会**立即返回**，**返回一个调用失败的信息**。 

（2）在内核缓冲区中**有数据的情况下，是阻塞的**，直到数据从内核缓冲复制到用户进程缓冲。复制完成后，**系统调用返回成功**，应用进程开始处理用户空间的缓存数据。

同步非阻塞IO的流程如下

![image-20210426141028691](images/image-20210426141028691.png)

举个例子。发起一个非阻塞socket的read读操作的系统调用，流程如下： 

（1）在内核数据没有准备好的阶段，用户线程发起IO请求时，立即返回。所以，为了读取到最终的数据，用户线程需要**不断地发起IO系统调用**。 

（2）内核数据到达后，用户线程发起系统调用，**用户线程阻塞**。内核开始复制数据，它会将数据从内核缓冲区复制到用户缓冲区（用户空间的内存），然后内核返回结果（例如返回复制到的用户缓冲区的字节数）。 

（3）**用户线程读到数据后，才会解除阻塞状态**，重新运行起来。也就是说，用户进程**需要经过多次的尝试，才能保证最终真正读到数据，而后继续执行**。

![img](images/6d5896af-95cc-4a5f-9c2a-e2110cba9425.png)

同步非阻塞IO的特点：应用程序的线程需要不断地进行IO系统调用，**轮询**数据是否已经准备好，如果没有准备好，就继续轮询，直到完成IO系统调用为止。



同步非阻塞IO的优点：每次发起的IO系统调用，在内核等待数据过程中**可以立即返回**。**用户线程不会阻塞，实时性较好**。



同步非阻塞IO的缺点：**不断地轮询内核**，这将占用大量的CPU时间，效率低下。



**NIO和BIO区别在于**

-  **BIO 一请求一线程，NIO一线程处理多请求**
- **BIO 是面向流**（同一时间只能读或写，阻塞），**NIO 是面向缓冲区**



Java的NIO（New IO），对应的不是四种基础IO模型中的NIO（None Blocking IO）模型，而是另外的一种模型，叫作IO多路复用模型（IO Multiplexing）。







## 异步AIO（Asynchronous IO）

> windows没有模仿linux，而是提供了被称为**IOCP**(**Input/Output Completion Port 输入输出完成端口**)的功能解决select性能的问题。
>
> IOCP采用异步非阻塞IO(AIO)的模型，其与epoll同步非阻塞IO的最大区别在于，epoll调用完成后，仅仅返回了就绪的文件描述符集合；而IOCP则在内核中自动的完成了epoll中原本应该由应用程序主动发起的I/O操作。



> 举个例子，当监听到就绪事件开始读取某一网络连接的请求报文时，epoll依然需要通过程序主动的发起读取请求，将数据从内核中读入用户空间。而windows下的IOCP则是通过注册回调事件的方式工作，由内核自动的将数据放入指定的用户空间，当处理完毕后会调度激活注册的回调事件，被唤醒的线程能直接访问到所需要的数据。
>
> 这也即BIO/NIO/IO多路复用被称为同步I/O，而IOCP被称为异步I/O的原因



异步IO模型（Asynchronous IO，简称为AIO）。

AIO的基本流程是：用户线程通过系统调用，向内核注册某个IO操作。

内核在整个IO操作（包括数据准备、数据复制）**完成后，通知用户程序**，用户执行后续的业务操作。

在异步IO模型中，在整个内核的数据处理过程中，包括内核将数据从网络物理设备（网卡）读取到内核缓冲区、将内核缓冲区的数据复制到用户缓冲区，用户程序**都不需要阻塞**。

异步IO模型流程：

![image-20210426143321620](images/image-20210426143321620.png)



举个例子。发起一个异步IO的read读操作的系统调用，流程如下： 

（1）当用户线程发起了read系统调用，立刻就可以开始去做**其他的事**，用户线程不阻塞。 

（2）内核就开始了IO的第一个阶段：准备数据。等到数据准备好了，内核就会将数据从内核缓冲区复制 到用户缓冲区（用户空间的内存）。 

（3）内核会给用户线程发送一个**信号**（Signal），或者**回调**用户线程注册的回调接口，告诉用户线程 read操作完成了。 

（4）用户线程读取用户缓冲区的数据，完成后续的业务操作。 



异步IO模型的特点：在内核等待数据和复制数据的两个阶段，**用户线程都不是阻塞的**。

用户线程需要接收内核的IO操作完成的事件，或者用户线程需要注册一个IO操作完成的回调函数。正因为如此，异步IO有的时候也被称为信号驱动IO。



 异步IO异步模型的缺点：应用程序**仅需要进行事件的注册与接收**，其余的工作都留给了操作系统，也就是说，需要**底层内核提供支持**。 理论上来说，异步IO是真正的异步输入输出，它的吞吐量高于IO多路复用模型的吞吐量。 就目前而言，Windows系统下通过IOCP实现了真正的异步IO。

而在Linux系统下，异步IO模型在2.6版本才引入，目前并不完善，其底层实现仍使用epoll，与IO多路复用相同，因此在性能上没有明显的优势。 大多数的高并发服务器端的程序，一般都是基于Linux系统的。因而，目前这类高并发网络应用程序的开发，大多采用IO多路复用模型。Netty框架，**使用的就是IO多路复用模型**，而不是异步IO模型。





## 总结

![img](images/6192c8de-2ddb-42cd-b786-dcf47cb88779.png)

